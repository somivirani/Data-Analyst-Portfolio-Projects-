{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250697c-d8fa-4907-b9e5-594019c2d76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62826ab1-9413-43a8-9f35-7ededbf612bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Make charts look nice\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All tools loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd46fb6-6bc8-4f06-a652-c39569866bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50b986-745f-4a3d-a35c-c81686e72e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load our stock data\n",
    "file_path = r\"D:\\TCS project\\TCS_stock_history - Copy.csv\"\n",
    "stock_data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"First few rows of our data:\")\n",
    "print(stock_data.head())\n",
    "print(f\"\\nOur data has {stock_data.shape[0]} rows and {stock_data.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cedc10-020c-423d-a68a-0f2cc22cf54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba84d72-8252-4f91-9897-c64ad2024157",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c70b9-eb71-4455-a1e9-a3d69c6c3aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be16e9-4b48-46db-9797-4f729a4abffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean up the data\n",
    "\"\"\"\n",
    "Real-world data can be messy. We need to:\n",
    "- Fix date format so computer understands it's dates\n",
    "- Handle missing values\n",
    "- Make sure numbers are actually numbers\n",
    "\"\"\"\n",
    "# Fix the date column\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# Sort by date (oldest to newest)\n",
    "stock_data = stock_data.sort_values('Date')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(stock_data.isnull().sum())\n",
    "\n",
    "# Fill any missing values with the previous day's data\n",
    "stock_data = stock_data.fillna(method='ffill')\n",
    "\n",
    "# Remove any remaining empty rows\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "print(f\"Clean data shape: {stock_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7749e55-2ec1-47bf-826c-8cff610d15df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3a9cc-d99a-4d0b-b3ba-ec0bb5da7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Explore our data - basic statistics\n",
    "\"\"\"\n",
    "Let's understand what our numbers look like - average prices, highest/lowest values, etc.\n",
    "This helps us spot any weird patterns or errors.\n",
    "\"\"\"\n",
    "print(\"Basic statistics of our stock data:\")\n",
    "print(stock_data[['Open', 'High', 'Low', 'Close', 'Volume']].describe())\n",
    "\n",
    "print(\"\\nFirst 5 rows after cleaning:\")\n",
    "print(stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132980c-1b61-4644-8608-c736beb129a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b4288-f90a-4c87-b0ac-e8a40d28bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 3: Moving averages (smoother lines that show trends)\n",
    "stock_data['30_day_avg'] = stock_data['Close'].rolling(window=30).mean()\n",
    "stock_data['200_day_avg'] = stock_data['Close'].rolling(window=200).mean()\n",
    "stock_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b029fe-b5e1-42d4-b2ff-46d39e49a74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a057e415-256b-4040-8937-0ca0782fa9ab",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### stock_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe6a8a-75da-4457-8833-7b9a8fb5d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 1: Stock price over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_data['Date'], stock_data['Close'], color='blue', linewidth=1)\n",
    "plt.title('TCS Stock Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf2b19-988c-429a-b5ff-2bfe7e63feaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad1a2c-e48f-4202-a1c5-a652804c02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2: Trading volume\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_data['Date'], stock_data['Volume'], color='green', alpha=0.7)\n",
    "plt.title('Trading Volume Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cfa97-2600-461e-b95c-e3b24d92cad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb4017-abee-45eb-b8ac-7df4f4e7a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(stock_data['Date'], stock_data['Close'], label='Daily Price', alpha=0.5)\n",
    "plt.plot(stock_data['Date'], stock_data['30_day_avg'], label='30-day Average', linewidth=2)\n",
    "plt.plot(stock_data['Date'], stock_data['200_day_avg'], label='200-day Average', linewidth=2)\n",
    "plt.title('Stock Price with Moving Averages')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c29fb-34e7-4f89-9405-2361addc5a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30013db9-7934-4553-bedd-63eedd984df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = stock_data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "# 2. Calculate correlations\n",
    "correlation_matrix = numeric_data.corr()\n",
    "# 3. Create the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "\n",
    "# 4. Add title and show\n",
    "plt.title('How Stock Factors Relate to Each Other')\n",
    "plt.show()\n",
    "\n",
    "print(\"Values close to 1 or -1 mean strong relationship. Values near 0 mean weak relationship.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245922cc-51af-4e68-9ba6-e304b65534f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c8f68-f5c9-45fa-987a-a2880f553e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create features for our prediction model\n",
    "\"\"\"\n",
    "To predict future prices, we need to create helpful indicators from existing data.\n",
    "We'll add things like:\n",
    "- Previous day's closing price\n",
    "- Moving averages  \n",
    "- Day of week effect\n",
    "\"\"\"\n",
    "# Add time-based features\n",
    "stock_data['year'] = stock_data['Date'].dt.year\n",
    "stock_data['month'] = stock_data['Date'].dt.month\n",
    "stock_data['day_of_week'] = stock_data['Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# Add previous day's close\n",
    "stock_data['previous_close'] = stock_data['Close'].shift(1)\n",
    "\n",
    "# Add daily price change\n",
    "stock_data['daily_change'] = stock_data['Close'].pct_change()\n",
    "\n",
    "# Add momentum indicator (MACD)\n",
    "stock_data['12_day_ema'] = stock_data['Close'].ewm(span=12).mean()\n",
    "stock_data['26_day_ema'] = stock_data['Close'].ewm(span=26).mean()\n",
    "stock_data['macd'] = stock_data['12_day_ema'] - stock_data['26_day_ema']\n",
    "\n",
    "# Remove rows with missing values from our calculations\n",
    "stock_data = stock_data.dropna()\n",
    "\n",
    "print(\"New features added successfully!\")\n",
    "print(f\"Data shape after adding features: {stock_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd0a1a-538e-4ae5-86cb-c57c9b6f809b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f2044-40db-4078-a769-7e5968a68ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Prepare data for machine learning\n",
    "\"\"\"\n",
    "We're setting up our prediction problem:\n",
    "- Features (X): What we use to make predictions\n",
    "- Target (y): What we're trying to predict (tomorrow's closing price)\n",
    "\"\"\"\n",
    "# Choose which features to use for prediction\n",
    "feature_columns = ['Open', 'High', 'Low', 'Volume', 'previous_close', \n",
    "                   '30_day_avg', 'macd', 'day_of_week', 'month']\n",
    "\n",
    "X = stock_data[feature_columns]  # Our input features\n",
    "y = stock_data['Close']           # What we want to predict\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# We use older data to train, newer data to test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} days\")\n",
    "print(f\"Testing set: {X_test.shape[0]} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb1710-b6d1-45be-80d5-46dbf80a227c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d7369-3ed9-42b0-aea7-521138b78736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Scale our data\n",
    "\"\"\"\n",
    "Machine learning models work better when all numbers are on similar scales.\n",
    "We'll adjust our data so no single feature dominates just because it has bigger numbers.\n",
    "\"\"\"\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, \"price_scaler.joblib\")\n",
    "\n",
    "print(\"Data scaled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882ed2a-6a03-41cf-afbe-51c834cb0d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d3109-17a8-4c6c-94e3-ae8772e3bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Build a simple linear regression model\n",
    "\"\"\"\n",
    "This is our baseline model - the simplest way to predict prices.\n",
    "It assumes a straight-line relationship between features and price.\n",
    "\"\"\"\n",
    "# Create and train the model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "linear_predictions = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate how good our predictions are\n",
    "linear_mae = mean_absolute_error(y_test, linear_predictions)\n",
    "linear_rmse = np.sqrt(mean_squared_error(y_test, linear_predictions))\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"Average prediction error: ‚Çπ{linear_mae:.2f}\")\n",
    "print(f\"Root mean squared error: ‚Çπ{linear_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e63228-e668-40a9-b937-20d7cc0a780c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998bf54-f7ed-446b-8af8-ee6a2999289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Build a random forest model\n",
    "\"\"\"\n",
    "Random Forest is more sophisticated - it can capture complex patterns \n",
    "by combining many decision trees.\n",
    "\"\"\"\n",
    "# Create and train the model\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    max_depth=15,      # How deep each tree can grow\n",
    "    random_state=42    # For reproducible results\n",
    ")\n",
    "forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "forest_predictions = forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate predictions\n",
    "forest_mae = mean_absolute_error(y_test, forest_predictions)\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_test, forest_predictions))\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Average prediction error: ‚Çπ{forest_mae:.2f}\")\n",
    "print(f\"Root mean squared error: ‚Çπ{forest_rmse:.2f}\")\n",
    "\n",
    "# Save this model since it's probably our best one\n",
    "joblib.dump(forest_model, \"tcs_forest_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4a0ad-af04-46de-a2d1-ffb85003faae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae072be-bc0f-4f53-a179-dee5e5de6f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cd479-72f7-482a-acb5-57670f7ca074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Visualize our predictions vs actual prices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reset indices to ensure they align properly\n",
    "y_test_reset = y_test.reset_index(drop=True)\n",
    "forest_predictions_series = pd.Series(forest_predictions, index=y_test_reset.index)\n",
    "\n",
    "# Get dates for our test period - make sure indices align\n",
    "test_dates = stock_data['Date'].iloc[-len(y_test):].reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_dates, y_test_reset.values, label='Actual Prices', color='blue', linewidth=2)\n",
    "plt.plot(test_dates, forest_predictions_series.values, label='Predicted Prices', color='red', linestyle='--')\n",
    "plt.title('TCS Stock: Actual vs Predicted Prices (Random Forest)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show which model performed better\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Linear Regression MAE: ‚Çπ{linear_mae:.2f}\")\n",
    "print(f\"Random Forest MAE:     ‚Çπ{forest_mae:.2f}\")\n",
    "print(f\"Improvement: {((linear_mae - forest_mae) / linear_mae * 100):.1f}% better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdbec0-0c29-4523-ab17-2c04d046adee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5acc04-e43d-4d20-a355-566b618e2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Visualize our predictions vs actual prices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simple approach - create a range of indices for plotting\n",
    "test_dates = range(len(y_test))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(test_dates, y_test.values, label='Actual Prices', color='blue', linewidth=2)\n",
    "plt.plot(test_dates, forest_predictions, label='Predicted Prices', color='red', linestyle='--')\n",
    "plt.title('TCS Stock: Actual vs Predicted Prices (Random Forest)')\n",
    "plt.xlabel('Test Sample Index')\n",
    "plt.ylabel('Price (‚Çπ)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show which model performed better\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Linear Regression MAE: ‚Çπ{linear_mae:.2f}\")\n",
    "print(f\"Random Forest MAE:     ‚Çπ{forest_mae:.2f}\")\n",
    "print(f\"Improvement: {((linear_mae - forest_mae) / linear_mae * 100):.1f}% better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47544fc2-c33d-445c-bff6-90cf5507a0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fc851-8ede-4e9f-a946-629323434e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Save our work and summarize\n",
    "\"\"\"\n",
    "Let's save everything we've created and summarize what we learned.\n",
    "\"\"\"\n",
    "# Save the linear model too\n",
    "joblib.dump(linear_model, \"tcs_linear_model.joblib\")\n",
    "\n",
    "print(\"üéâ Analysis Complete! Summary:\")\n",
    "print(\"‚úì Data loaded and cleaned\")\n",
    "print(\"‚úì Trends visualized with charts\") \n",
    "print(\"‚úì Features created for prediction\")\n",
    "print(\"‚úì Two models trained and compared\")\n",
    "print(\"‚úì Best model saved for future use\")\n",
    "print(f\"‚úì Final prediction error: ‚Çπ{forest_mae:.2f} per share\")\n",
    "\n",
    "print(\"\\nüìÅ Files created:\")\n",
    "print(\"- tcs_forest_model.joblib (main prediction model)\")\n",
    "print(\"- tcs_linear_model.joblib (simple baseline model)\") \n",
    "print(\"- price_scaler.joblib (data scaler for new predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38934d6c-4b9a-4b31-bbc3-b37775cee793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2a993-4898-4090-8db0-3b469ef21d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: How to use your saved model for new predictions\n",
    "\"\"\"\n",
    "Once you have new stock data, here's how to use your trained model:\n",
    "\"\"\"\n",
    "def predict_tcs_price(new_data, model_path=\"tcs_forest_model.joblib\", scaler_path=\"price_scaler.joblib\"):\n",
    "    \"\"\"\n",
    "    Predict TCS closing price for new data\n",
    "    new_data should have the same columns as our feature_columns\n",
    "    \"\"\"\n",
    "    # Load the model and scaler\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Scale the new data\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(new_data_scaled)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Example of how to use it:\n",
    "print(\"To make new predictions, use the predict_tcs_price() function\")\n",
    "print(\"Make sure your new data has these columns:\", feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89092f0e-8d65-412e-b093-9a808f9da638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954bd2f-636d-4404-ac73-5ee648017f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61a8bd-6f66-475c-afa1-88374f7debc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac0902-2f3c-47c3-b7ee-69eb5a083ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375756c-6419-419e-9865-2f4076020db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c13ba4-185d-4975-b426-5577babb3e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81d43a-9505-47a0-89df-c974032a17be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071113de-e425-4f4a-a501-056407d38784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12fc04-a489-4e86-862f-4cef18a10135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35a975-454b-4436-a35c-a6f199020f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10ed7f-e2c4-4dd6-b157-5c1665ee2f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bb5da-fa5d-44fd-ba9d-c16962f6973d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
